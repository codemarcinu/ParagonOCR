# ğŸ“š ParagonWeb - PeÅ‚na Dokumentacja

## Spis treÅ›ci

1. [Wprowadzenie](#wprowadzenie)
2. [Architektura](#architektura)
3. [Instalacja](#instalacja)
4. [Konfiguracja](#konfiguracja)
5. [UÅ¼ytkowanie](#uÅ¼ytkowanie)
6. [API Reference](#api-reference)
7. [Deweloperzy](#deweloperzy)
8. [Troubleshooting](#troubleshooting)
9. [FAQ](#faq)

---

## Wprowadzenie

**ParagonWeb** to nowoczesna aplikacja webowa do zarzÄ…dzania paragonami zakupowymi. Aplikacja automatycznie ekstrahuje dane z paragonÃ³w (PDF, PNG, JPG), kategoryzuje produkty, Å›ledzi stan magazynowy i oferuje inteligentnego asystenta kulinarnego.

### GÅ‚Ã³wne funkcjonalnoÅ›ci

- ğŸ“„ **Automatyczne przetwarzanie paragonÃ³w** - OCR + AI parsowanie
- ğŸ“¦ **ZarzÄ…dzanie magazynem** - Åšledzenie produktÃ³w, dat waÅ¼noÅ›ci
- ğŸ“Š **Analityka zakupÃ³w** - Statystyki, wykresy, trendy
- ğŸ¦… **Asystent Bielik** - AI asystent kulinarny z RAG
- ğŸŒ **Interfejs webowy** - DziaÅ‚a w przeglÄ…darce, responsywny
- ğŸ³ **Docker ready** - Åatwa instalacja i deployment

### Wymagania systemowe

**Minimalne:**
- Python 3.13+ (lub Docker)
- 2GB RAM
- 1GB wolnego miejsca na dysku

**Zalecane:**
- Python 3.13+
- 4GB RAM
- 5GB wolnego miejsca
- DostÄ™p do internetu (dla trybu Cloud)

---

## Architektura

### Komponenty

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ParagonWeb                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  NiceGUI     â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”¤   FastAPI    â”‚            â”‚
â”‚  â”‚  Frontend    â”‚  HTTP   â”‚   Backend    â”‚            â”‚
â”‚  â”‚  (Port 8080) â”‚         â”‚  (Port 8000) â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                         â”‚
â”‚         â”‚                        â”‚                      â”‚
â”‚         â–¼                        â–¼                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚      ReceiptParser (Core Logic)      â”‚             â”‚
â”‚  â”‚  - OCR Providers (Mistral/Tesseract) â”‚             â”‚
â”‚  â”‚  - AI Providers (OpenAI/Ollama)     â”‚             â”‚
â”‚  â”‚  - Database (SQLite)                 â”‚             â”‚
â”‚  â”‚  - Business Logic                    â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### PrzepÅ‚yw danych

1. **Upload paragonu** â†’ Frontend (NiceGUI)
2. **Przetwarzanie** â†’ Backend (FastAPI)
3. **OCR** â†’ Mistral OCR API lub Tesseract (lokalnie)
4. **Parsowanie** â†’ OpenAI API lub Ollama (lokalnie)
5. **Zapis** â†’ SQLite Database
6. **WyÅ›wietlenie** â†’ Frontend

### Tryby dziaÅ‚ania

#### Tryb Cloud (DomyÅ›lny)
- **OCR:** Mistral OCR API
- **AI:** OpenAI API (GPT-4o-mini)
- **Zalety:** Brak instalacji, wysoka jakoÅ›Ä‡, dziaÅ‚a wszÄ™dzie
- **Wymagania:** Klucze API (Mistral + OpenAI)

#### Tryb Lokalny
- **OCR:** Tesseract (lokalnie)
- **AI:** Ollama (lokalnie)
- **Zalety:** Brak kosztÃ³w, peÅ‚na kontrola
- **Wymagania:** Tesseract + Ollama z modelami

---

## Instalacja

### Metoda 1: Docker (Zalecana)

**Krok 1:** Sklonuj repozytorium
```bash
git clone <repo-url>
cd ParagonOCR
git checkout feature/web-app-transformation
```

**Krok 2:** UtwÃ³rz plik `.env` (opcjonalnie)
```bash
cd ReceiptParser
cat > .env << EOF
USE_CLOUD_AI=true
USE_CLOUD_OCR=true
OPENAI_API_KEY=sk-...
MISTRAL_API_KEY=...
EOF
```

**Krok 3:** Uruchom Docker
```bash
cd ..
docker-compose up --build
```

**Krok 4:** OtwÃ³rz przeglÄ…darkÄ™
- Frontend: http://localhost:8080
- Backend API: http://localhost:8000
- Dokumentacja API: http://localhost:8000/docs

### Metoda 2: Instalacja lokalna

**Krok 1:** Przygotuj Å›rodowisko
```bash
python3.13 -m venv venv
source venv/bin/activate  # Linux/Mac
# lub
venv\Scripts\activate  # Windows
```

**Krok 2:** Zainstaluj zaleÅ¼noÅ›ci
```bash
cd ReceiptParser
pip install -r requirements.txt
```

**Krok 3:** Konfiguracja
```bash
# UtwÃ³rz plik .env
cat > .env << EOF
USE_CLOUD_AI=true
USE_CLOUD_OCR=true
OPENAI_API_KEY=sk-...
MISTRAL_API_KEY=...
EOF
```

**Krok 4:** Inicjalizuj bazÄ™ danych
```bash
python -m ReceiptParser.src.main init-db
```

**Krok 5:** Uruchom aplikacjÄ™
```bash
# Terminal 1: Backend
cd ..
python server.py

# Terminal 2: Frontend
python web_app.py
```

### Metoda 3: Tryb lokalny (bez Cloud API)

#### Opcja A: Docker (Zalecane)

**Krok 1:** Uruchom z konfiguracjÄ… lokalnÄ…
```bash
docker-compose -f docker-compose.local.yml up -d --build
```

**Krok 2:** Pobierz modele Ollama (pierwszy raz)
```bash
# Ollama automatycznie pobierze modele przy pierwszym uÅ¼yciu
# Lub rÄ™cznie:
docker exec -it paragon_ollama ollama pull llava:latest
docker exec -it paragon_ollama ollama pull SpeakLeash/bielik-11b-v2.3-instruct:Q4_K_M
```

**Uwaga:** W Dockerze Ollama jest w osobnym kontenerze i komunikuje siÄ™ przez sieÄ‡ Docker.

#### Opcja B: Lokalna instalacja

**Wymagania:**
- Tesseract OCR: `sudo apt-get install tesseract-ocr tesseract-ocr-pol`
- Ollama: https://ollama.ai/download

**Konfiguracja:**
```bash
# .env
USE_CLOUD_AI=false
USE_CLOUD_OCR=false
OLLAMA_HOST=http://localhost:11434
VISION_MODEL=llava:latest
TEXT_MODEL=SpeakLeash/bielik-11b-v2.3-instruct:Q4_K_M
```

**Uruchom Ollama:**
```bash
ollama serve
# W osobnym terminalu:
ollama pull llava:latest
ollama pull SpeakLeash/bielik-11b-v2.3-instruct:Q4_K_M
```

---

## Konfiguracja

### Zmienne Å›rodowiskowe

Plik `.env` w katalogu `ReceiptParser/`:

```env
# === Tryb dziaÅ‚ania ===
USE_CLOUD_AI=true          # true = OpenAI, false = Ollama
USE_CLOUD_OCR=true        # true = Mistral OCR, false = Tesseract

# === Ollama (tylko dla USE_CLOUD_AI=false) ===
# W Dockerze automatycznie ustawiane na http://ollama:11434
# Lokalnie: http://localhost:11434
OLLAMA_HOST=http://localhost:11434

# === Cloud API Keys ===
OPENAI_API_KEY=sk-...     # Wymagane jeÅ›li USE_CLOUD_AI=true
MISTRAL_API_KEY=...       # Wymagane jeÅ›li USE_CLOUD_OCR=true

# === Lokalne ustawienia (dla USE_CLOUD_AI=false) ===
OLLAMA_HOST=http://localhost:11434
VISION_MODEL=llava:latest
TEXT_MODEL=SpeakLeash/bielik-11b-v2.3-instruct:Q4_K_M
OLLAMA_TIMEOUT=300

# === Opcjonalne ===
ENABLE_FILE_LOGGING=true  # Logi do pliku
```

### Uzyskanie kluczy API

#### OpenAI API Key
1. PrzejdÅº na https://platform.openai.com/api-keys
2. Zaloguj siÄ™ lub utwÃ³rz konto
3. Kliknij "Create new secret key"
4. Skopiuj klucz (zaczyna siÄ™ od `sk-`)
5. **Uwaga:** Klucz jest widoczny tylko raz!

**Koszty:** ~$0.15 za 1M tokenÃ³w (GPT-4o-mini), typowe uÅ¼ycie: ~5 PLN/miesiÄ…c

#### Mistral API Key
1. PrzejdÅº na https://console.mistral.ai/
2. Zaloguj siÄ™ lub utwÃ³rz konto
3. PrzejdÅº do "API Keys"
4. UtwÃ³rz nowy klucz
5. Skopiuj klucz

**Koszty:** Darmowy tier dostÄ™pny, pÅ‚atne: ~$0.01 za stronÄ™ OCR

### Konfiguracja przez UI

MoÅ¼esz rÃ³wnieÅ¼ skonfigurowaÄ‡ aplikacjÄ™ przez interfejs webowy:
1. OtwÃ³rz http://localhost:8080/ustawienia
2. PrzeÅ‚Ä…cz tryby Cloud/Lokalny
3. WprowadÅº klucze API
4. Kliknij "Zapisz ustawienia"

---

## UÅ¼ytkowanie

### Dashboard

**Dodawanie paragonu:**
1. Kliknij "Wybierz plik paragonu"
2. Wybierz plik (PNG, JPG, PDF)
3. Plik zostanie automatycznie przesÅ‚any i przetworzony
4. PostÄ™p przetwarzania jest widoczny na pasku postÄ™pu

**Statystyki:**
- ÅÄ…czna liczba paragonÃ³w
- Suma wydatkÃ³w
- Liczba pozycji
- Ostatnie paragony

### Magazyn

**PrzeglÄ…d produktÃ³w:**
- Lista wszystkich produktÃ³w w magazynie
- IloÅ›Ä‡, jednostka, data waÅ¼noÅ›ci
- Kategoria produktu
- Status (OK, WkrÃ³tce przeterminowany, Przeterminowany)

**Filtrowanie:**
- Sortowanie po dacie waÅ¼noÅ›ci
- Wyszukiwanie po nazwie

### Bielik - Asystent Kulinarny

**Funkcje:**
- Odpowiadanie na pytania o jedzenie
- Propozycje potraw na podstawie dostÄ™pnych produktÃ³w
- Generowanie list zakupÃ³w
- Wyszukiwanie produktÃ³w w bazie

**PrzykÅ‚ady pytaÅ„:**
- "Co mam do jedzenia?"
- "Co mogÄ™ zrobiÄ‡ na obiad?"
- "Czy mam mleko w magazynie?"
- "Jakie potrawy mogÄ™ przygotowaÄ‡?"

### Ustawienia

**Tryb dziaÅ‚ania:**
- PrzeÅ‚Ä…cznik Cloud AI (OpenAI) / Lokalny (Ollama)
- PrzeÅ‚Ä…cznik Cloud OCR (Mistral) / Lokalny (Tesseract)

**Klucze API:**
- Pole na OpenAI API Key
- Pole na Mistral API Key
- Klucze sÄ… ukryte (password field)

---

## API Reference

### Base URL
```
http://localhost:8000
```

### Endpointy

#### POST /api/upload
Przetwarza przesÅ‚any paragon.

**Request:**
```http
POST /api/upload
Content-Type: multipart/form-data

file: <plik>
```

**Response:**
```json
{
  "task_id": "uuid-string",
  "status": "processing"
}
```

**Status zadania:**
```http
GET /api/task/{task_id}
```

**Response:**
```json
{
  "status": "completed|processing|error",
  "progress": 0-100,
  "message": "Status message"
}
```

#### GET /api/receipts
Zwraca listÄ™ paragonÃ³w.

**Query Parameters:**
- `skip` (int, default: 0) - Liczba paragonÃ³w do pominiÄ™cia
- `limit` (int, default: 50) - Maksymalna liczba paragonÃ³w

**Response:**
```json
{
  "receipts": [
    {
      "paragon_id": 1,
      "sklep": "Lidl",
      "data_zakupu": "2025-01-15",
      "suma_paragonu": 123.45,
      "liczba_pozycji": 10,
      "plik_zrodlowy": "/path/to/file.pdf"
    }
  ],
  "total": 1
}
```

#### GET /api/stats
Zwraca statystyki zakupÃ³w.

**Response:**
```json
{
  "total_statistics": {
    "total_receipts": 50,
    "total_spent": 5000.00,
    "total_items": 500,
    "avg_receipt": 100.00
  },
  "by_store": [
    {"name": "Lidl", "amount": 2000.00}
  ],
  "by_category": [
    {"name": "NabiaÅ‚", "amount": 500.00}
  ],
  "top_products": [
    {"name": "Mleko", "count": 20, "total": 200.00}
  ],
  "monthly": [
    {
      "month": "StyczeÅ„ 2025",
      "receipts": 10,
      "spent": 1000.00
    }
  ]
}
```

#### GET /api/inventory
Zwraca stan magazynu.

**Response:**
```json
{
  "inventory": [
    {
      "produkt_id": 1,
      "nazwa": "Mleko",
      "ilosc": 2.0,
      "jednostka": "l",
      "data_waznosci": "2025-01-20",
      "zamrozone": false,
      "kategoria": "NabiaÅ‚"
    }
  ]
}
```

#### POST /api/chat
WysyÅ‚a wiadomoÅ›Ä‡ do asystenta Bielik.

**Request:**
```json
{
  "question": "Co mam do jedzenia?"
}
```

**Response:**
```json
{
  "answer": "Masz w magazynie: mleko, chleb, jajka..."
}
```

#### GET /api/settings
Zwraca aktualne ustawienia.

**Response:**
```json
{
  "use_cloud_ai": true,
  "use_cloud_ocr": true,
  "openai_api_key_set": true,
  "mistral_api_key_set": true
}
```

#### POST /api/settings
Aktualizuje ustawienia.

**Request:**
```json
{
  "use_cloud_ai": true,
  "use_cloud_ocr": true,
  "openai_api_key": "sk-...",
  "mistral_api_key": "..."
}
```

**Response:**
```json
{
  "message": "Ustawienia zaktualizowane"
}
```

### Dokumentacja interaktywna

- **Swagger UI:** http://localhost:8000/docs
- **ReDoc:** http://localhost:8000/redoc

---

## Deweloperzy

### Struktura projektu

```
ParagonOCR/
â”œâ”€â”€ server.py                 # FastAPI backend
â”œâ”€â”€ web_app.py                # NiceGUI frontend
â”œâ”€â”€ Dockerfile                # Docker configuration
â”œâ”€â”€ docker-compose.yml        # Docker orchestration
â”œâ”€â”€ ReceiptParser/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ ai_providers.py   # AI provider abstractions
â”‚   â”‚   â”œâ”€â”€ ocr_providers.py  # OCR provider abstractions
â”‚   â”‚   â”œâ”€â”€ config.py         # Configuration
â”‚   â”‚   â”œâ”€â”€ main.py           # Main processing pipeline
â”‚   â”‚   â”œâ”€â”€ bielik.py         # Bielik assistant
â”‚   â”‚   â”œâ”€â”€ llm.py            # LLM integration
â”‚   â”‚   â”œâ”€â”€ database.py       # Database models
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ requirements.txt      # Dependencies
â””â”€â”€ tests/                    # Testy
```

### Dodawanie nowego dostawcy AI

```python
# ReceiptParser/src/ai_providers.py

class CustomAIProvider(AIProvider):
    def chat(self, model, messages, format=None, options=None, images=None):
        # Implementacja
        pass
    
    def is_available(self):
        # SprawdÅº dostÄ™pnoÅ›Ä‡
        return True
```

### Dodawanie nowego dostawcy OCR

```python
# ReceiptParser/src/ocr_providers.py

class CustomOCRProvider(OCRProvider):
    def extract_text(self, image_path: str) -> str:
        # Implementacja
        pass
    
    def is_available(self):
        # SprawdÅº dostÄ™pnoÅ›Ä‡
        return True
```

### Testowanie

```bash
# Uruchom testy
pytest tests/

# Z coverage
pytest --cov=ReceiptParser tests/
```

### RozwÃ³j lokalny

```bash
# Backend w trybie dev (auto-reload)
uvicorn server:app --reload --host 0.0.0.0 --port 8000

# Frontend w trybie dev
python web_app.py --reload
```

---

## Troubleshooting

### Problem: "Dostawca AI nie jest dostÄ™pny"

**RozwiÄ…zanie:**
1. **Tryb Cloud:**
   - SprawdÅº czy `OPENAI_API_KEY` jest ustawiony
   - SprawdÅº czy klucz jest poprawny: `curl https://api.openai.com/v1/models -H "Authorization: Bearer $OPENAI_API_KEY"`

2. **Tryb Lokalny:**
   - **W Dockerze:**
     - SprawdÅº czy kontener Ollama dziaÅ‚a: `docker ps | grep ollama`
     - SprawdÅº logi: `docker logs paragon_ollama`
     - SprawdÅº dostÄ™pnoÅ›Ä‡: `docker exec paragon_ollama curl http://localhost:11434/api/tags`
   - **Lokalnie:**
     - SprawdÅº czy Ollama dziaÅ‚a: `curl http://localhost:11434/api/tags`
     - SprawdÅº czy model jest pobrany: `ollama list`

### Problem: "Dostawca OCR nie jest dostÄ™pny"

**RozwiÄ…zanie:**
1. **Tryb Cloud:**
   - SprawdÅº czy `MISTRAL_API_KEY` jest ustawiony
   - SprawdÅº czy klucz jest poprawny: `curl https://api.mistral.ai/v1/models -H "Authorization: Bearer $MISTRAL_API_KEY"`

2. **Tryb Lokalny:**
   - SprawdÅº czy Tesseract jest zainstalowany: `tesseract --version`
   - SprawdÅº czy jÄ™zyk polski jest zainstalowany: `tesseract --list-langs`

### Problem: "BÅ‚Ä…d poÅ‚Ä…czenia z API"

**RozwiÄ…zanie:**
1. SprawdÅº czy backend dziaÅ‚a: `curl http://localhost:8000/`
2. SprawdÅº logi: `docker-compose logs` lub `./logs/`
3. SprawdÅº porty: `netstat -tuln | grep 8000`

### Problem: "Baza danych nie istnieje"

**RozwiÄ…zanie:**
```bash
python -m ReceiptParser.src.main init-db
```

### Problem: "Docker build fails"

**RozwiÄ…zanie:**
1. SprawdÅº czy Docker dziaÅ‚a: `docker ps`
2. SprawdÅº logi builda: `docker-compose build --no-cache`
3. SprawdÅº czy porty sÄ… wolne: `lsof -i :8000 -i :8080`

### Problem: "Upload pliku nie dziaÅ‚a"

**RozwiÄ…zanie:**
1. SprawdÅº czy katalog `uploads/` istnieje i ma uprawnienia zapisu
2. SprawdÅº rozmiar pliku (max 50MB)
3. SprawdÅº format pliku (tylko PNG, JPG, PDF)

---

## FAQ

### P: Ile kosztuje uÅ¼ycie aplikacji?

**O:** W trybie Cloud:
- Mistral OCR: Darmowy tier lub ~$0.01/strona
- OpenAI: ~$0.15 za 1M tokenÃ³w (GPT-4o-mini)
- **Typowe uÅ¼ycie domowe: ~5 PLN/miesiÄ…c**

W trybie lokalnym: **0 PLN** (wymaga wÅ‚asnego sprzÄ™tu)

### P: Czy mogÄ™ uÅ¼ywaÄ‡ aplikacji bez internetu?

**O:** Tak, w trybie lokalnym (Ollama + Tesseract). Wymaga:
- Zainstalowanego Tesseract
- Uruchomionego Ollama z modelami

### P: Jakie formaty plikÃ³w sÄ… obsÅ‚ugiwane?

**O:** 
- Obrazy: PNG, JPG, JPEG
- Dokumenty: PDF

### P: Czy dane sÄ… bezpieczne?

**O:** 
- Wszystkie dane sÄ… przechowywane lokalnie (SQLite)
- Klucze API sÄ… przechowywane w zmiennych Å›rodowiskowych
- W trybie Cloud, obrazy sÄ… wysyÅ‚ane do API (Mistral/OpenAI)
- **Rekomendacja:** UÅ¼ywaj trybu lokalnego dla wraÅ¼liwych danych

### P: Jak zrobiÄ‡ backup danych?

**O:**
```bash
# Backup bazy danych
cp ReceiptParser/data/receipts.db ReceiptParser/data/receipts.db.backup

# Backup caÅ‚ego katalogu danych
tar -czf backup.tar.gz ReceiptParser/data/
```

### P: Czy mogÄ™ uruchomiÄ‡ aplikacjÄ™ na serwerze?

**O:** Tak! Docker pozwala na Å‚atwy deployment:
```bash
# Na serwerze
git clone <repo>
cd ParagonOCR
docker-compose up -d
```

### P: Jak zaktualizowaÄ‡ aplikacjÄ™?

**O:**
```bash
# Docker
docker-compose pull
docker-compose up -d --build

# Lokalnie
git pull
pip install -r ReceiptParser/requirements.txt --upgrade
```

### P: Czy mogÄ™ uÅ¼ywaÄ‡ wÅ‚asnych modeli AI?

**O:** Tak! W trybie lokalnym moÅ¼esz uÅ¼ywaÄ‡ dowolnych modeli Ollama:
```env
VISION_MODEL=twoj-model:latest
TEXT_MODEL=twoj-model:latest
```

---

## Wsparcie

- **Issues:** GitHub Issues
- **Dokumentacja:** Ten plik
- **API Docs:** http://localhost:8000/docs

---

**Wersja dokumentacji:** 1.0.0  
**Ostatnia aktualizacja:** 2025-11-23

