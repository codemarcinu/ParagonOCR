# Konfiguracja Ollama
OLLAMA_HOST=http://localhost:11434

# Modele
# Model wizyjny do odczytu paragonu (musi obsługiwać obrazy, np. llava, bakllava)
VISION_MODEL=llava:latest

# Model tekstowy do normalizacji nazw produktów (instrukcyjny, np. bielik, mistral, llama3)
TEXT_MODEL=SpeakLeash/bielik-11b-v2.3-instruct:Q4_K_M
