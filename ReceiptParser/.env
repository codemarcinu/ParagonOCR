# Konfiguracja Ollama
OLLAMA_HOST=http://localhost:11434

# Modele
# Model wizyjny do odczytu paragonu (musi obsługiwać obrazy, np. llava, bakllava)
VISION_MODEL=llava:latest

# Model tekstowy do normalizacji nazw produktów (instrukcyjny, np. bielik, mistral, llama3)
TEXT_MODEL=SpeakLeash/bielik-11b-v2.3-instruct:Q4_K_M

# Klucz API do Mistral OCR (wymagany dla opcji mistral-ocr)
MISTRAL_API_KEY=SWXiOSaZxtrVGJw0PKrNLJVjqzkg1q4m

# Tryb działania - false = używa Ollama, true = używa OpenAI
USE_CLOUD_AI=false
USE_CLOUD_OCR=false
